{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82a50e9-6e0c-480a-ba5f-b26dd03eb28d",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "This notebook aims to explain LLM, Prompt Engineering and working with Langchain framework using LCEL . I wish you a good learning :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ca775-ef8a-4c39-875a-3a125bfa8d45",
   "metadata": {},
   "source": [
    "## LLM\n",
    "It simply means Large Langage Model. LLM is a AI model which has been trained on a wide or various data. As LLM , we can note:\n",
    "* IBM Watson\n",
    "* LLaMa of Facebook\n",
    "* Chatgpt (surrely the most known)\n",
    "LLMs are useful for achieving a lot of tasks. Indeed , they are able to \n",
    "* understand Human Langage through NLP(Natural Langage Processing),\n",
    "* See some images through Computer vision. As a matter of fact, they detect some diseases on scanner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75669ba-ed2c-4307-9a58-5aacc0ced4f1",
   "metadata": {},
   "source": [
    "# Prompt Engeniering\n",
    "We can see Prompt Engineering as the science of implementing some well-formed or useful input which are intended for or aimed at LLM. Actually \n",
    ",it allows LLM to generate suitable output. Prompt Engineering is just a driver which leads LLM response. Since LLMs have been on range of data ,\n",
    "Prompt Engineering is useful for getting suitable response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7508e1-2b80-4aaf-a5c7-b534cba3a572",
   "metadata": {},
   "source": [
    "## In-Context-Learning\n",
    "LLM learns from examples which have been added in prompt . We dont need to retrain it or updating its weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f6f7ef86-2516-4609-846c-56703a23e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser,JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99e50c-4ef4-4403-8a6e-9369c30b2f7f",
   "metadata": {},
   "source": [
    "# Prompt template\n",
    "It allows us to use template for our prompts. That way ,we can reuse it . Lets see some types of prompt template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d2605d-43d0-4da6-bafe-0caef2cde6d7",
   "metadata": {},
   "source": [
    "# Zero Shot template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5df2fac4-9d1a-4ff6-bfa7-62fbf475f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a agriculture expert. Explain this :{concept}\n",
    "like you speak to a child\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "promptZeroShot= PromptTemplate(\n",
    "    input_variables = ['concept'],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ee7b70-75b2-49c8-85f0-0288e165bf42",
   "metadata": {},
   "source": [
    "## Lets see the result of promptZeroShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c22f4ed-424f-4dc5-af9e-f22923ed0e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['concept'], input_types={}, partial_variables={}, template='\\nYou are a agriculture expert. Explain this :{concept}\\nlike you speak to a child\\nAnswer:\\n')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptZeroShot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06d0016-54da-460b-b7b6-4c0b1e046f73",
   "metadata": {},
   "source": [
    "# One shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eee6a3b5-387b-4181-a29a-8d2bd4508c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "templateOneshot = \"\"\"\n",
    "You are an expert . I will give you some samples of sentences and emotion it leads\n",
    "Phrase 1: I dont like your behavior\n",
    "it express a disapointment\n",
    "\n",
    "Tell which sentiment is expressed in this sentence {sentence}\n",
    "\"\"\"\n",
    "\n",
    "promptOneShot = PromptTemplate(\n",
    "    input_variables=['sentence'],\n",
    "    template= templateOneshot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a63b6b-20a6-4773-b9c8-f0a03ba7cd4d",
   "metadata": {},
   "source": [
    "# Other type of prompting template\n",
    "* Few shot :Like One shot but we give more samples\n",
    "* CoT (Chain of thought): We foaster the model to split a particular problems in some step-by-step or process to get a final output\n",
    "* Self-Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da636e63-d450-4429-a3dc-a1f897afe9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We can see the model response to our promptZeroShot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67cd0f95-3d80-40d5-b979-3485552e4643",
   "metadata": {},
   "outputs": [],
   "source": [
    "responseAgri = client.chat(model='llama3', messages=[{'role': 'user', 'content': promptZeroShot.format(concept='planting')}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8e1d4ca1-c3d0-4c20-8600-575d3fc4e1e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Little buddy! So, you know how we need food to eat every day? Like fruits and vegetables? Well, plants grow those yummy foods for us! And planting is the special way we help them grow.\n",
      "\n",
      "Planting is like giving a little home to a tiny seed. We take that seed, and we put it in the ground, with some dirt and water around it. Then, we give it some love and care, so it can grow into a big strong plant!\n",
      "\n",
      "Think of it like building a block tower. You start with one block, then you add another, and another, until your tower gets really tall! With plants, we start with a small seed, then we help it grow bigger and stronger by giving it the right food (like sunlight and water), and keeping it safe from harm.\n",
      "\n",
      "There are lots of special things we do to help plants grow:\n",
      "\n",
      "1. **Seeding**: We put the tiny seeds in the ground.\n",
      "2. **Watering**: We give them a drink, so they don't get thirsty!\n",
      "3. **Sunlight**: We make sure they get plenty of sunshine, like when you play outside on a sunny day!\n",
      "4. **Fertilizing**: We add special food to help them grow big and strong.\n",
      "\n",
      "By doing these things, we can help plants grow into all sorts of yummy foods, like apples, carrots, tomatoes, and more! And the best part is, we get to enjoy eating those foods too!\n",
      "\n",
      "So, that's what planting is like! It's like giving a little home to a tiny seed, and helping it grow into something amazing.\n"
     ]
    }
   ],
   "source": [
    "print(responseAgri['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31e9a6f-03de-45f7-8a26-aa4fe68b9bc3",
   "metadata": {},
   "source": [
    "# LCEL: LangChain Expression Langage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08324d7a-f77d-4db3-9e71-041cbe95a727",
   "metadata": {},
   "source": [
    "## Output parser\n",
    "It sets the format of response output. Among them , we have\n",
    "* JsonOutputParser\n",
    "* CvOutputParser\n",
    "* StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e970f2ee-6308-4d7c-8dfb-33e1b921871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model='llama3')\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cd49686e-0ce2-4952-aff1-1021214302cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = promptZeroShot | llm | parser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "19b4d9cc-473b-4fc2-9d16-37e570861fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "responseChain = chain.invoke({'concept':'engrais'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e29bc84-f7c0-49ea-84dc-1763909026b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay! Let's talk about ENGRAIS!\n",
      "\n",
      "So, you know how we need food to eat, right? Like fruits and veggies and grains like bread?\n",
      "\n",
      "Well, plants need food too! And that's where ENGRAIS comes in.\n",
      "\n",
      "Engrais is just a fancy word for FERTILIZER. It's like special food for the plants that helps them grow big and strong.\n",
      "\n",
      "Just like how we need vitamins and minerals to be healthy, plants need certain nutrients to grow well. And that's where engrais comes in!\n",
      "\n",
      "Engrais has all sorts of good stuff like nitrogen, phosphorus, and potassium that help plants make leaves, stems, and roots. It's like a special boost for the plant's growth!\n",
      "\n",
      "Farmers use engrais to help their crops grow big and healthy. They put it on the soil around the plants, and it helps the plants absorb all the good nutrients they need.\n",
      "\n",
      "Just like how we take medicine when we're sick, farmers use engrais to keep their plants healthy and strong. And that means we get yummy food to eat!\n",
      "\n",
      "So, that's what engrais is! It's like a special food for plants that helps them grow big and strong.\n"
     ]
    }
   ],
   "source": [
    "print(responseChain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f200d650-30af-47e7-b95a-be577403fea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "842aa50c-25bb-44ac-90dd-09ef73889d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"you are an expert in agriculture\"),\n",
    "    (\"user\",\"respond to this question:{question} like you explain to a {user_type}. If you dont know , say it instead of giving falsy response\")\n",
    "])\n",
    "\n",
    "chain2 = prompt | llm | parser \n",
    "\n",
    "input_ = {\"question\":\"how to increase his productivity\",\"user_type\":\"kid\"}\n",
    "\n",
    "response2 = chain2.invoke(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ae46ac86-f8ae-4de0-8782-d91f37801b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed result:\n",
      "Title: The Matrix\n",
      "Director: The Wachowskis\n",
      "Year: 1999\n",
      "Genre: Science Fiction\n"
     ]
    }
   ],
   "source": [
    "# Jsonoutputparser\n",
    "\n",
    "\n",
    "# Create your JSON parser\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "# Create more explicit format instructions\n",
    "format_instructions = \"\"\"RESPONSE FORMAT: Return ONLY a single JSON object—no markdown, no examples, no extra keys.  It must look exactly like:\n",
    "{\n",
    "  \"title\": \"movie title\",\n",
    "  \"director\": \"director name\",\n",
    "  \"year\": 2000,\n",
    "  \"genre\": \"movie genre\"\n",
    "}\n",
    "\n",
    "IMPORTANT: Your response must be *only* that JSON.  Do NOT include any illustrative or example JSON.\"\"\"\n",
    "\n",
    "# Create your prompt template with clearer instructions\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"You are a JSON-only assistant.\n",
    "\n",
    "Task: Generate info about the movie \"{movie_name}\" in JSON format.\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\",\n",
    "    input_variables=[\"movie_name\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "# Create the chain without cleaning step\n",
    "movie_chain = prompt_template | llm | json_parser\n",
    "\n",
    "# Test with a movie name\n",
    "movie_name = \"The Matrix\"\n",
    "result = movie_chain.invoke({\"movie_name\": movie_name})\n",
    "\n",
    "# Print the structured result\n",
    "print(\"Parsed result:\")\n",
    "print(f\"Title: {result['title']}\")\n",
    "print(f\"Director: {result['director']}\")\n",
    "print(f\"Year: {result['year']}\")\n",
    "print(f\"Genre: {result['genre']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ad813-c7ff-4277-8c1d-422d5693efb6",
   "metadata": {},
   "source": [
    "# Document\n",
    "Langchain allows us to handle documents. It contains 2 part:\n",
    "* page_content: We put there the document text\n",
    "* Metadata: It contains some informations about the document. It can be id, author ...It is not obliged to set this params\n",
    "\n",
    "# Documents loader\n",
    "They aimed at load documents . It can be pdf , html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cbdf7f18-1b60-4eac-867e-2b07e1f860eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import PyPDFLoader ,WebBaseLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "68ea2d41-44ba-4d89-b7d7-a9c1fe9c61bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Math is wonderful' metadata={'document_id': '99', 'document_author': 'Paul yves etiens'}\n"
     ]
    }
   ],
   "source": [
    "document  = Document(\n",
    "    page_content='Math is wonderful',\n",
    "    metadata={\n",
    "        \"document_id\":\"99\",\n",
    "        \"document_author\":\"Paul yves etiens\"\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cfcf70b7-041d-4383-bc24-5560f1c4729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content=\"* corresponding author - jkim72@kent.edu \\nRevolutionizing Mental Health Care through \\nLangChain: A Journey with a Large Language \\nModel\\nAditi Singh \\n Computer Science  \\n Cleveland State University  \\n a.singh22@csuohio.edu \\nAbul Ehtesham  \\nThe Davey Tree Expert \\nCompany  \\nabul.ehtesham@davey.com \\nSaifuddin Mahmud  \\nComputer Science & \\nInformation Systems  \\n Bradley University  \\nsmahmud@bradley.edu  \\nJong-Hoon Kim* \\n Computer Science,  \\nKent State University,  \\njkim72@kent.edu \\nAbstract— Mental health challenges are on the rise in our \\nmodern society, and the imperative to address mental disorders, \\nespecially regarding anxiety, depression, and suicidal thoughts, \\nunderscores the need for effective interventions. This paper \\ndelves into the application of recent advancements in pretrained \\ncontextualized language models to introduce MindGuide, an \\ninnovative chatbot serving as a mental health assistant for \\nindividuals seeking guidance and support in these critical areas. \\nMindGuide lever ages the capabilities of LangChain and its \\nChatModels, specifically Chat OpenAI, as the bedrock of its \\nreasoning engine. The system incorporates key features such as \\nLangChain's ChatPrompt Template, HumanMessage  Prompt \\nTemplate, ConversationBufferMemory, and LLMChain, \\ncreating an advanced solution for early detection and \\ncomprehensive support within the field of mental health. \\nAdditionally, the paper discusses the implementation of \\nStreamlit to enhance the user ex perience and interaction with \\nthe chatbot. Th is novel approach holds great promise for \\nproactive mental health intervention and assistance. \\nKeywords —Large Language models , LangChain, Chatbot, \\nPretrained models, Mental health, Mental health support. \\nI. INTRODUCTION \\nThe issue of mental health is an international situation, \\naffecting people in each particularly developed nations and \\nemerging markets. According to the World Health \\nOrganization's Mental Health Action Plan (2013-2020), it's far \\nestimated that around one in four humans international face  \\nnumerous kinds of mental disorders. This statistic underscores \\nthe vast nature of mental health demanding situations \\nthroughout extraordinary demographic businesses and areas. \\nHowever, what makes this situation even extra complex is \\nthe concerning truth that three out of each four people dealing \\nwith severe intellectual disorders do no longer have get entry \\nto the necessary remedy they require. This remedy gap \\nintensifies the weight of intellectual health troubles, leaving a \\nsizable part of the populace without the assist and care needed \\nto efficiently address their intellectual health issues. \\nFurthermore, periods like the recent global pandemic, the \\neffect of mental health issues becomes even more said. The \\nCOVID-19 pandemic, in particular, has highlighted how \\npublic health crises can extensively have an effect on mental \\nproperly-being. During such hard instances, a widespread part \\nof the population faces extended problems in having access to \\nmental fitness professionals. This emphasizes the urgent want \\nfor progressed intellectual health offerings and support \\nstructures. It underscores the urgency of addressing the mental \\nhealth disaster and developing complete answers to make \\ncertain that people global have the means to successfully deal \\nwith their mental fitness challenges.. \\nIn studies [1], it's pretty clear that there's a deep connection \\nbetween mental troubles and the chances of someone taking \\ntheir own life. And when you look at the big picture, it's quite \\nshocking - nearly a million people across the globe end their \\nlives every year, especially the young ones, making it the \\nsecond biggest reason for their passing . It's intriguing that \\nwhen someone attempts suicide, they often grapple with \\nmental challenges. It's like shifting from struggling with \\ndifficult thoughts to considering ending everything. This shift \\nis observable in how people express themselves and \\ninteract[2]. \\nOne practical approach to addressing mental illness and \\npreventing suicidal ideation is early identification. Recent \\nadvancements in deep learning have facilitated the \\ndevelopment of effective early detection methods [3]. A \\nnotable trend in natural language processing (NLP)  involves \\nthe use of contextualized pretrained language models  [4], \\nwhich have garnered substantial attention for their \\neffectiveness in various text processing tasks. \\nThis paper delves into the application of these recent \\nadvancements in pretrained contextualized large language \\nmodels to introduce MindGuide, an innovative chatbot \\ndesigned to function as a mental health assistant for \\nindividuals in need of guidance and support in these critical \\nareas. MindGuide relies on the capabilities of LangChain and \\nits ChatModels  [5], specifically Chat OpenAI [6], as the \\nfoundation of its reasoning engine. The system incorporates \\nkey components such as LangChain’s ChatPrompt Template \\n[7], HumanMessage , PromptTemplate, ConversationBuffer \\nMemory, and LLMChain [8], creating an advanced solution \\nfor early detection and comprehensive support within the field \\nof mental health. Additionally, the paper discusses the \\nimplementation of Streamlit to enhance the user experience \\nand interaction with the chatbot. \\nThe remainder of the paper is arranged accordingly. In \\nSection II, LangChain and its important components  are \\nintroduced. T he proposed methodology for developing the \\nwhole architecture is described  in Section III . Section IV \\nprovides an overview of Streamlit. Section V provides an \\nillustration of sequential interaction of MindGuide chatbot \\nand human. The conclusion is drawn in Section V. \\nII. LANGCHAIN \\nLangChain, with its open -source essence, emerges as a \\npromising solution, aiming to simplify the complex process of \\ndeveloping applications powered by large language models \\n(LLMs). This framework though the rapid delivery of building \\nblocks and pre-built chains for building large language model \\napplications shows the easy way developers can do it.\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2'}, page_content='LangChain helps us to unlock the ability to harness the \\nLLM’s immense potential in tasks such as document analysis, \\nchatbot development, code analysis, and countless other \\napplications. Whether your desire is to unlock deeper natural \\nlanguage understanding , enhance data, or circumvent \\nlanguage barriers through translation, LangChain is ready to \\nprovide the tools and programming support you need to do \\nwithout it that it is not only difficult but also fresh for you. Its \\ncore functionalities encompass: \\n1. Context-Aware Capabilities: LangChain facilitates the \\ndevelopment of applications that are inherently \\ncontext-aware. This means that these applications can \\nconnect to a language model and draw from various \\nsources of context, such as prompt instructions, a few-\\nshot examples, or existing content, to ground their \\nresponses effectively. \\n2. Reasoning Abilities: LangChain equips applications \\nwith the capacity to reason effectively. By relying on a \\nlanguage model, these applications can make informed \\ndecisions about how to respond based on the provided \\ncontext and determine the appropriate actions to take. \\nLangChain offers several key value propositions: \\nModular Components: It provides abstractions that \\nsimplify working with language models, along with a \\ncomprehensive collection of implementations for each \\nabstraction. These components are designed to be modular \\nand user -friendly, making them useful whethe r you are \\nutilizing the entire LangChain framework or not. \\nOff-the-Shelf Chains: LangChain offers pre -configured \\nchains, which are structured assemblies of components \\ntailored to accomplish specific high -level tasks. These pre -\\ndefined chains streamline the initial setup process and serve as \\nan ideal starting point for your projects. The MindGuide Bot \\nuses below components from LangChain. \\nA. ChatModel \\nWithin LangChain, a ChatModel is a specific kind of \\nlanguage model crafted to manage conversational \\ninteractions. Unlike traditional language models that take one \\nstring as input and generate a single string as output, \\nChatModels operate with a list of mes sages as input, \\ngenerating a message as output. \\nEach message in the list has two parts: the content and the \\nrole. The content is the actual text or substance of the message, \\nwhile the role denotes the role or source of the message (such \\nas \"User,\" \"Assistant,\" \"System,\" etc.). \\nThis approach with ChatModels opens the door to more \\ndynamic and interactive conversations with the language \\nmodel. It empowers the creation of chatbot applications, \\ncustomer support systems, or any other application involving \\nmulti-turn conversations. We utilized the ChatOpenAI \\nChatModel to create MindGuide chatbots specifically \\ndesigned to function as mental health therapists. In our \\ninteraction with OpenAI, we opted for an OpenAI API key to \\nengage with the ChatGpt3 turbo model and utilized a \\ntemperature value of 0.5. The steps to create an OpenAI API \\nkey are outlined [9].  \\nB. Message \\nIn the context of LangChain, messages  [10] refer to a list of \\nmessages that are used as input when interacting with a \\nChatModel. Each message in the list represents a specific turn \\nor exchange in a conversation. Each message in the messages \\nlist typically consists of two components: \\n• content: This represents the actual text or content of \\nthe message. It can be a user query, a system \\ninstruction, or any other relevant information. \\n• role: This represents the role or source of the \\nmessage. It defines who is speaking or generating \\nthe message. Common roles include \"User\", \\n\"Assistant\", \"System\", or any other custom role you \\ndefine. \\nThe chat model interface is based around messages rather \\nthan raw text. The types of messages supported in LangChain \\nare SystenMessage, HumanMessage, and AIMessage. \\nSystemMessage is the ChatMessage coming from the system \\nin its LangChain template  as illustrated in Figure 1. Human \\nMessage is a  ChatMessage coming from a human/user.  \\nAIMessage is a ChatMessage coming from an AI/assistant as \\nillustrated in Figure 2.  \\n \\n                   Figure 1. A System Message illustration  \\nYou are a compassionate and experienced mental \\nhealth therapist with a proven track record of \\nhelping patients overcome anxiety and other mental \\nhealth challenges. Your primary objective is to \\nsupport the patient in addressing their concerns \\nand guiding them towards positive change. In this \\ninteractive therapy session, you will engage with \\nthe patient by asking open -ended questions, \\nactively listening to their responses, and providing \\nempathetic feedback. Your approach is \\ncollaborative, and you strive to cr eate a safe and \\nnon-judgmental space for the patient to share their \\nthoughts and feelings. \\nAs the patient shares their struggles, you will \\nprovide insightful guidance and evidence -based \\nstrategies tailored to their unique needs. You may \\nalso offer practical exercises or resources to help \\nthem manage their symptoms and improve their \\nmental wellbeing. When necessary, you will gently \\nredirect the conversation back to the patient\\'s \\nprimary concerns related to anxiety, mental health, \\nor family issues. This ensures that each session is \\nproductive and focused on addressing the most \\npressing issues. Thro ughout the session, you \\nremain mindful of the patient\\'s emotional state and \\nadjust your approach accordingly. \\nYou recognize that everyone\\'s journey is \\ndifferent, and that progress can be incremental.  \\nBy building trust and fostering a strong \\ntherapeutic relationship, you empower the patient \\nto take ownership of their growth and development. \\nAt the end of the session, you will summarize key \\npoints from your discussion, highlighting the \\npatient\\'s strengths and areas for improvement. \\nTogether, you will set achievable goals for future \\nsessions, reinforcing a sense of hope and \\nmotivation. Your ultimate goal is to equip the \\npatient with the tools and skills needed to navigate \\nlife\\'s challenges with confidence and resilience.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}, page_content='Figure 2. An AIMessage illustration \\nC. Prompt Template \\nPrompt templates [10] allow you to structure input for LLMs. \\nThey provide a convenient way to format user inputs and \\nprovide instructions to generate responses. Prompt templates \\nhelp ensure that the LLM understands the desired context and \\nproduces relevant outputs. \\nThe prompt template classes in LangChain are built to \\nmake constructing prompts with dynamic inputs easier. Of \\nthese classes, the simplest is the PromptTemplate. \\nD. Chain \\nChains [11] in LangChain refer to the combination of \\nmultiple components to achieve specific tasks. They provide \\na structured and modular approach to building language \\nmodel applications. By combining different components, you \\ncan create chains that address various u se cases and \\nrequirements. Here are some advantages of using chains: \\n• Modularity: Chains allow you to break down \\ncomplex tasks into smaller, manageable \\ncomponents. Each component can be developed and \\ntested independently, making it easier to maintain \\nand update the application. \\n• Simplification: By combining components into a \\nchain, you can simplify the overall implementation \\nof your application. Chains abstract away the \\ncomplexity of working with individual components, \\nproviding a higher-level interface for developers. \\n• Debugging: When an issue arises in your \\napplication, chains can help pinpoint the \\nproblematic component. By isolating the chain and \\ntesting each component individually, you can \\nidentify and troubleshoot any errors or unexpected \\nbehavior. \\n• Maintenance: Chains make it easier to update or \\nreplace specific components without affecting the \\nentire application. If a new version of a component \\nbecomes available or if you want to switch to a \\ndiffer. \\nTo build a chain, you simply combine the desired components \\nin the order they should be executed. Each component in the \\nchain takes the output of the previous component as input, \\nallowing for a seamless flow of data and interaction with the \\nlanguage model. \\nE. Memory  \\nThe ability to remember prior exchanges conversation is \\nreferred to as memory  [12]. LangChain includes several \\nprograms for increasing system memory. These utilities can \\nbe used independently or as a part of a chain.  We call this \\nability to store information about past interactions \"memory\". \\nLangChain provides a lot of utilities for adding memory to a \\nsystem. These utilities can be used by themselves or \\nincorporated seamlessly into a chain. \\nA memory system must support two fundamental \\nactions: reading and writing. Remember that each chain has \\nsome fundamental execution mechanism that requires \\nspecific inputs. Some of these inputs are provided directly by \\nthe user, while others may be retrieve d from memory. In a \\nsingle run, a chain will interact with its memory system twice. \\n1. A chain will READ from its memory system and \\naugment the user inputs AFTER receiving the initial \\nuser inputs but BEFORE performing the core logic. \\n2. After running the basic logic but before providing the \\nsolution, a chain will WRITE the current run\\'s inputs \\nand outputs to memory so that they may be referred \\nto in subsequent runs. \\nAny memory system\\'s two primary design decisions are: \\n1. How state is stored ? \\nStoring: List of chat messages: A history of all chat \\nexchanges is behind each memory. Even if not all of \\nthese are immediately used, they must be preserved \\nin some manner. A series of integrations for storing \\nthese conversation messages, ranging from in -\\nmemory lists to persistent databases, is a significant \\ncomponent of the LangChain memory module. \\n2. How state is queried ? \\nQuerying: Data structures and algorithms on top of \\nchat messages: Keeping track of chat messages is a \\nsimple task. What is less obvious are the data \\nstructures and algorithms built on top of chat \\nconversations to provide the most usable view of \\nthose chats. \\nA simple memory system may only return the most \\nrecent messages on each iteration. A slightly more \\ncomplicated memory system may return a brief summary of \\nthe last K messages. A more complex system might extract \\nentities from stored messages and only retur n information \\nabout entities that have been referenced in the current run. \\nThere are numerous sorts of memories. Each has its own set \\nof parameters and return types and is helpful in a variety of \\nsituations.  \\nMemory Types:  \\n• ConversationBufferMemory allows for saving \\nmessages and then extracts the messages in a \\nvariable. \\n• ConversationBufferWindowMemory keeps a list of \\nthe interactions of the conversation over time. It only \\nuses the last K interactions. This can be useful for \\nkeeping a sliding window of the most recent \\ninteractions, so the buffer does not get too large. \\nThe MindGuide chatbot uses conversation buffer memory. \\nThis memory allows for storing messages and then extracts \\nthe messages in a variable. \\nIII. ARCHITETURE \\nIn crafting the architecture of the MindGuide app, each \\nstep is meticulously designed to create a seamless and \\neffective user experience for those seeking mental health \\nsupport. The user interface, built on Streamlit, sets the tone \\nwith a friendly and safe welcome. Users can jump in by typing \\nWelcome! to your therapy session. I\\'m here to listen, \\nsupport, and guide you through any mental health \\nchallenges or concerns you may have. Please feel free \\nto share what\\'s on your mind, and we\\'ll work together \\nto address your needs. Remember, this is a safe and \\nconfidential space for you to express y ourself. Let\\'s \\nbegin when you\\'re ready.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf', 'total_pages': 6, 'page': 3, 'page_label': '4'}, page_content='their mental health questions, kicking off a series of \\ninteractions with the LangChain framework. This is where the \\nmagic happens – LangChain acts as the brain behind the \\nchatbot, working through various components like chat \\nmessage templates and a memory concept to create a \\npersonalized and responsive support system.  Each step is \\nbroken down. \\nStep 1. User Interface:  Developed using the Streamlit \\nframework, the user interface welcomes users with a \\nmessage explaining the role of the chatbot in providing \\nmental health support. It assures users of a safe and \\nconfidential space to express their concerns.  \\nStep 2. User Input - Prompt: Users can input mental health-\\nrelated questions or seek advice by typing their queries \\ninto the input box integrated into the Streamlit interface. \\nStep 3. Data Transfer to LangChain: Implement the \\nfunctionality that sends the user\\'s input (question) as a \\nchat prompt template to the LangChain framework. This \\ninput serves as the \"human message prompt\" template. \\nStep 4. LangChain Framework: In this phase, the LangChain \\nframework serves as the backbone of the chatbot, where \\nall the foundational components and building blocks are \\nmeticulously orchestrated. Here\\'s a deeper dive into the \\ncritical elements of LangChain Processing: \\n• ChatMessage and Prompt Templates:  Within \\nLangChain, the chatbot\\'s core communication \\ninfrastructure is established by  creating \\nChatMessage and prompt templates for optimal \\nchatbot engagement. \\n• LLMChain and LLM Model Interaction:  To \\nfacilitate interactions with the large language \\nmodel (LLM), a specialized component called \\nLLMChain is constructed. The LLMChain acts \\nas a conduit for managing the flow of \\nconversation between the chatbot and the LLM \\nmodel, in this case, GPT-4. \\n• The LLMChain handles both the user\\'s queries \\nand the chatbot\\'s responses, allowing for a \\ndynamic and coherent conversation flow. \\n• Chatmodel Class of LangChain: The LangChain \\nframework leverages the Chatmodel  class, a \\ncritical component for interfacing with the \\nOpenAI model (GPT-4) for making requests to \\nthe language model and processing its \\nresponses, ensuring seamless communication \\nbetween the chatbot and the AI model. \\n• Memory Concept:  To enhance the chatbot\\'s \\nconversational capabilities and provide context-\\naware responses, LangChain incorporates a \\nmemory concept that allows the chatbot to retain \\nand access information from past interactions \\nwithin a session. The memory function enhances \\nconversations by retaining user queries, \\npreferences, and contextual details, thereby \\ncontributing to a more effective and \\npersonalized interaction . This way, it tailors \\nresponses based on the user\\'s history throughout \\nthe session. \\nStep 5. Utilize the user\\'s question as input to construct a \\nchain of prompts that the large language model (in this \\ncase, GPT-4) will process. \\nStep 6. Model Response:  Dispatch the constructed input \\nchain to the GPT -4 model for natural language \\nunderstanding and generation.  The GPT -4 model \\ngenerates a response based on the input and context. \\nStep 7. Response to Streamlit:  Receive the response \\ngenerated by the GPT -4 model and transmit it back to \\nthe Streamlit framework for display to the user. \\nStep 8. User Response Delivery:  Present the model -\\ngenerated response to the user, thereby delivering the \\nmental health advice or information they sought.\\n \\nFigure 3. MindGuide Chatbot Architecture'), Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf', 'total_pages': 6, 'page': 4, 'page_label': '5'}, page_content=\"IV. STREAMLIT \\nStreamlit [13] is a faster way to build and share data apps. \\nStreamlit turns data scripts into shareable web apps in \\nminutes. Streamlit is an open -source Python library that \\nsimplifies the process of designing and sharing visually \\nappealing web applications, particularly well -suited for \\napplications involving machine learning and data science.  \\nLeveraging Streamlit's Python-based development approach, \\nyou can harness the power of Python to build a responsive and \\ndynamic web application. This is advantageous for developers \\nfamiliar with Python, as it allows for quick and efficient \\ndevelopment. \\n \\nV. MINDGUIDE CHATBOT INTERACTION  \\nThe MindGuide Bot interaction is illustrated in Fig. 4, \\ndepicting the following key elements:  \\n• Welcome screen interface with AI message and \\nthe initial human interaction with MindGuide \\nChatbot (Fig. 4a). \\n• MindGuide Chatbot's AI response to the human \\nmessage, followed by the human's mental health \\nquestion (Fig. 4b). \\n• MindGuide Chatbot's AI response to the \\nsubsequent human message, followed by another \\nmental health question from the human (Fig. 4c). \\n• MindGuide Chatbot's AI response after \\nanalyzing the latest human message (Fig. 4d). \\n \\n   s \\n                                                         (a)      (b) \\n      \\n                                                         (c)      (d) \\nFigure 4. Sequential Interaction with MindGuide Chatbot - (a) Welcome screen and initial AI message, (b) AI response to the first human message and \\nmental health question, (c) Subsequent AI response and continued interaction with another human mental health question, (d) AI response after analyzing the \\nlatest human message. \\nVI. CONCLUSION \\nThis paper employs the OpenAI chat model GPT-4 with a \\ntemperature setting of 0.5 to serve as an initial therapist, \\nproviding support for patients dealing with mental health \\nissues such as depression and anxiety. MindGuide relies on \\nthe ChatOpenAI model from LangChain as its foundation , \\nincorporating innovative features like ChatPrompt Template, \\nHuman Message Prompt Template, Conversation Buffer \\nMemory, and LLMChain to proactively identify issues and \\ndeliver comprehensive assistance. In the next phase, we plan \\nto enhance this chatbot fu rther by implementing Retrieval -\\nAugmented Generation (RAG) and incorporating embedding \\nvectors for frequently asked questions related to mental health.\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf', 'total_pages': 6, 'page': 5, 'page_label': '6'}, page_content='REFERENCES \\n[1] K. Windfuhr and N. Kapur, \"Suicide and mental illness: a clinical \\nreview of 15 years findings from the UK National Confidential Inquiry \\ninto Suicide,\" British medical bulletin, vol. 100, pp. 101-121, 2011. \\n[2] M. D. Choudhury, E. Kiciman, M. Dredze, G. Coppersmith, and M. \\nKumar, \"Discovering shifts to suicidal ideation from mental health \\ncontent in social media,\" in Proceedings of the 2016 CHI Conference \\non Human Factors in Computing Systems, 2016, pp. 2098-2110. \\n[3] S. Ji, C. P. Yu, S. F. Fung, S. Pan, and G. Long, \"Supervised learning \\nfor suicidal ideation detection in online user content,\" Complex, 2018. \\n[4] LangChain, https://www.langchain.com/ (accessed Nov. 29, 2023). \\n[5] LangChain ChatModels, https://blog.langchain.dev/chat-models/ \\n(accessed Nov. 29, 2023). \\n[6] LangChain with OpenAI Chat Model, \\nhttps://python.langchain.com/docs/integrations/chat/openai/ (accessed \\nNov. 29, 2023). \\n[7] LangChain’s Prompt, https://python.langchain.com/docs/modules \\n/model_io/prompts/ (accessed Nov. 29, 2023). \\n[8] LangChain’s Chains, https://python.langchain.com/docs/modules \\n/chains (accessed Nov. 29, 2023). \\n[9] OpenAI, https://platform.openai.com/docs/quickstart?context=python \\n(accessed Nov. 29, 2023). \\n[10] LangChain’s Message Prompt Template,  \\nhttps://python.langchain.com/docs/modules/model_io/prompts/messa\\nge_prompts (accessed Nov. 29, 2023). \\n[11] LangChain’s Large Language Model Chain,  \\nhttps://python.langchain.com/docs/modules/chains/foundational/llm_c\\nhain (accessed Nov. 29, 2023). \\n[12] Streamlit, https://streamlit.io/ (accessed Nov. 29, 2023).')]\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf\")\n",
    "\n",
    "doc = loader.load()\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9d2d7aa9-0967-4799-a425-80431e50e3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Figure 2. An AIMessage illustration \n",
      "C. Prompt Template \n",
      "Prompt templates [10] allow you to structure input for LLMs. \n",
      "They provide a convenient way to format user inputs and \n",
      "provide instructions to generate responses. Prompt templates \n",
      "help ensure that the LLM understands the desired context and \n",
      "produces relevant outputs. \n",
      "The prompt template classes in LangChain are built to \n",
      "make constructing prompts with dynamic inputs easier. Of \n",
      "these classes, the simplest is the PromptTemplate. \n",
      "D. Chain \n",
      "Chains [11] in LangChain refer to the combination of \n",
      "multiple components to achieve specific tasks. They provide \n",
      "a structured and modular approach to building language \n",
      "model applications. By combining different components, you \n",
      "can create chains that address various u se cases and \n",
      "requirements. Here are some advantages of using chains: \n",
      "• Modularity: Chains allow you to break down \n",
      "complex tasks into smaller, manageable \n",
      "components. Each component can be developed and \n",
      "tested independently, making it easier to maintain \n",
      "and update the application. \n",
      "• Simplification: By combining components into a \n",
      "chain, you can simplify the overall implementation \n",
      "of your application. Chains abstract away the \n",
      "complexity of working with individual components, \n",
      "providing a higher-level interface for developers. \n",
      "• Debugging: When an issue arises in your \n",
      "application, chains can help pinpoint the \n",
      "problematic component. By isolating the chain and \n",
      "testing each component individually, you can \n",
      "identify and troubleshoot any errors or unexpected \n",
      "behavior. \n",
      "• Maintenance: Chains make it easier to update or \n",
      "replace specific components without affecting the \n",
      "entire application. If a new version of a component \n",
      "becomes available or if you want to switch to a \n",
      "differ. \n",
      "To build a chain, you simply combine the desired components \n",
      "in the order they should be executed. Each component in the \n",
      "chain takes the output of the previous component as input, \n",
      "allowing for a seamless flow of data and interaction with the \n",
      "language model. \n",
      "E. Memory  \n",
      "The ability to remember prior exchanges conversation is \n",
      "referred to as memory  [12]. LangChain includes several \n",
      "programs for increasing system memory. These utilities can \n",
      "be used independently or as a part of a chain.  We call this \n",
      "ability to store information about past interactions \"memory\". \n",
      "LangChain provides a lot of utilities for adding memory to a \n",
      "system. These utilities can be used by themselves or \n",
      "incorporated seamlessly into a chain. \n",
      "A memory system must support two fundamental \n",
      "actions: reading and writing. Remember that each chain has \n",
      "some fundamental execution mechanism that requires \n",
      "specific inputs. Some of these inputs are provided directly by \n",
      "the user, while others may be retrieve d from memory. In a \n",
      "single run, a chain will interact with its memory system twice. \n",
      "1. A chain will READ from its memory system and \n",
      "augment the user inputs AFTER receiving the initial \n",
      "user inputs but BEFORE performing the core logic. \n",
      "2. After running the basic logic but before providing the \n",
      "solution, a chain will WRITE the current run's inputs \n",
      "and outputs to memory so that they may be referred \n",
      "to in subsequent runs. \n",
      "Any memory system's two primary design decisions are: \n",
      "1. How state is stored ? \n",
      "Storing: List of chat messages: A history of all chat \n",
      "exchanges is behind each memory. Even if not all of \n",
      "these are immediately used, they must be preserved \n",
      "in some manner. A series of integrations for storing \n",
      "these conversation messages, ranging from in -\n",
      "memory lists to persistent databases, is a significant \n",
      "component of the LangChain memory module. \n",
      "2. How state is queried ? \n",
      "Querying: Data structures and algorithms on top of \n",
      "chat messages: Keeping track of chat messages is a \n",
      "simple task. What is less obvious are the data \n",
      "structures and algorithms built on top of chat \n",
      "conversations to provide the most usable view of \n",
      "those chats. \n",
      "A simple memory system may only return the most \n",
      "recent messages on each iteration. A slightly more \n",
      "complicated memory system may return a brief summary of \n",
      "the last K messages. A more complex system might extract \n",
      "entities from stored messages and only retur n information \n",
      "about entities that have been referenced in the current run. \n",
      "There are numerous sorts of memories. Each has its own set \n",
      "of parameters and return types and is helpful in a variety of \n",
      "situations.  \n",
      "Memory Types:  \n",
      "• ConversationBufferMemory allows for saving \n",
      "messages and then extracts the messages in a \n",
      "variable. \n",
      "• ConversationBufferWindowMemory keeps a list of \n",
      "the interactions of the conversation over time. It only \n",
      "uses the last K interactions. This can be useful for \n",
      "keeping a sliding window of the most recent \n",
      "interactions, so the buffer does not get too large. \n",
      "The MindGuide chatbot uses conversation buffer memory. \n",
      "This memory allows for storing messages and then extracts \n",
      "the messages in a variable. \n",
      "III. ARCHITETURE \n",
      "In crafting the architecture of the MindGuide app, each \n",
      "step is meticulously designed to create a seamless and \n",
      "effective user experience for those seeking mental health \n",
      "support. The user interface, built on Streamlit, sets the tone \n",
      "with a friendly and safe welcome. Users can jump in by typing \n",
      "Welcome! to your therapy session. I'm here to listen, \n",
      "support, and guide you through any mental health \n",
      "challenges or concerns you may have. Please feel free \n",
      "to share what's on your mind, and we'll work together \n",
      "to address your needs. Remember, this is a safe and \n",
      "confidential space for you to express y ourself. Let's \n",
      "begin when you're ready.' metadata={'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}\n"
     ]
    }
   ],
   "source": [
    "print(doc[2]) # That way we can see the second page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0ede240d-bdaa-4a3c-8f9f-7db19cd110de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atbot in providing \n",
      "mental health support. It assures users of a safe and \n",
      "confidential space to express their concerns.  \n",
      "Step 2. User Input - Prompt: Users can input mental health-\n",
      "related questions or seek advice by typing their queries \n",
      "into the input box integrated into the Streamlit interface. \n",
      "Step 3. Data Transfer to LangChain: Implement the \n",
      "functionality that sends the user's input (question) as a \n",
      "chat prompt template to the LangChain framework. This \n",
      "input serves as the \"human message prompt\" template. \n",
      "Step 4. LangChain Framework: In this phase, the LangChain \n",
      "framework serves as the backbone of the chatbot, where \n",
      "all the foundational components and building blocks are \n",
      "meticulously orchestrated. Here's a deeper dive into the \n",
      "critical elements of LangChain Processing: \n",
      "• ChatMessage and Prompt Templates:  Within \n",
      "LangChain, the chatbot's core communication \n",
      "infrastructure is established by  creating \n",
      "ChatMessage and prompt templates for optimal \n",
      "chatbot engagement. \n",
      "• LLMChain and LLM Model Interaction:  To \n",
      "facilitate interactions with the large language \n",
      "model (LLM), a specialized component called \n",
      "LLMChain is constructed. The LLMChain acts \n",
      "as a conduit for managing the flow of \n",
      "conversation between the chatbot and the LLM \n",
      "model, in this case, GPT-4. \n",
      "• The LLMChain handles both the user's queries \n",
      "and the chatbot's responses, allowing for a \n",
      "dynamic and coherent conversation flow. \n",
      "• Chatmodel Class of LangChain: The LangChain \n",
      "framework leverages the Chatmodel  class, a \n",
      "critical component for interfacing with the \n",
      "OpenAI model (GPT-4) for making requests to \n",
      "the language model and processing its \n",
      "responses, ensuring seamless communication \n",
      "between the chatbot and the AI model. \n",
      "• Memory Concept:  To enhance the chatbot's \n",
      "conversational capabilities and provide context-\n",
      "aware responses, LangChain incorporates a \n",
      "memory concept that allows the chatbot to retain \n",
      "and access information from past interactions \n",
      "within a session. The memory function enhances \n",
      "conversations by retaining user queries, \n",
      "preferences, and contextual details, thereby \n",
      "contributing to a more effective and \n",
      "personalized interaction . This way, it tailors \n",
      "responses based on the user's history throughout \n",
      "the session. \n",
      "Step 5. Utilize the user's question as input to construct a \n",
      "chain of prompts that the large language model (in this \n",
      "case, GPT-4) will process. \n",
      "Step 6. Model Response:  Dispatch the constructed input \n",
      "chain to the GPT -4 model for natural language \n",
      "understanding and generation.  The GPT -4 model \n",
      "generates a response based on the input and context. \n",
      "Step 7. Response to Streamlit:  Receive the response \n",
      "generated by the GPT -4 model and transmit it back to \n",
      "the Streamlit framework for display to the user. \n",
      "Step 8. User Response Delivery:  Present the model -\n",
      "generated response to the user, thereby delivering the \n",
      "mental health advice or information they sought.\n",
      " \n",
      "Figure 3. MindGuide Chatbot Architecture\n"
     ]
    }
   ],
   "source": [
    "print(doc[3].page_content[500:]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233fb1f7-532c-4533-a10c-fcf976d57ed7",
   "metadata": {},
   "source": [
    "# Loading a website content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fd4fd31c-f5b6-41a8-9d78-c180c4c07eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain overview - Docs by LangChainSkip to main contentWe've raised a $125M Series B to build the platform for agent engineering. Read more.Docs by LangChain home pageLangChain + LangGraphSearch...⌘KGitHubTry LangSmithTry LangSmithSearch...NavigationLangChain overviewLangChainLangGraphDeep AgentsIntegrationsLearnReferenceContributePythonOverviewLangChain v1.0Release notesMigration guideGet startedInstallQuickstartPhilosophyCore componentsAgentsModelsMessagesToolsShort-term memoryStreamingMiddlewareStructured outputAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol (MCP)Human-in-the-loopMulti-agentRetrievalLong-term memoryUse in productionStudioTestDeployAgent Chat UI\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://python.langchain.com/v0.2/docs/introduction/\")\n",
    "\n",
    "web_data = loader.load()\n",
    "\n",
    "print(web_data[0].page_content[:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "65c3ad83-2f05-48bb-9f91-ab1a5260f3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk length 147\n",
      "challenges or concerns you may have. Please feel free \n",
      "to share what's on your mind, and we'll work together \n",
      "to address your needs. Remember, this is a safe and\n"
     ]
    }
   ],
   "source": [
    "# chunk_overlap=20, That way, we keep context\n",
    "text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20, separator=\"\\n\")\n",
    "\n",
    "chunks = text_splitter.split_documents(doc)\n",
    "\n",
    "print('Chunk length',len(chunks))\n",
    "print(chunks[100].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b23e28d-d136-4a66-8e8c-d4c997671fe0",
   "metadata": {},
   "source": [
    "# Loading a document and splitting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "948c1d92-f858-4c67-a473-27de541b27db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Splitter 1 Statistics ===\n",
      "Total number of chunks: 95\n",
      "Average chunk size: 263.80 characters\n",
      "Metadata keys preserved: author, source, creator, title, total_pages, producer, page_label, page, creationdate, moddate\n",
      "\n",
      "Example chunk:\n",
      "Content (first 150 chars): comprehensive support within the field of mental health. \n",
      "Additionally, the paper discusses the implementation of \n",
      "Streamlit to enhance the user ex pe...\n",
      "Metadata: {'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}\n",
      "Min chunk size: 49 characters\n",
      "Max chunk size: 299 characters\n",
      "\n",
      "=== Splitter 2 Statistics ===\n",
      "Total number of chunks: 71\n",
      "Average chunk size: 353.62 characters\n",
      "Metadata keys preserved: author, source, creator, title, total_pages, producer, page_label, page, creationdate, moddate\n",
      "\n",
      "Example chunk:\n",
      "Content (first 150 chars): affecting people in each particularly developed nations and \n",
      "emerging markets. According to the World Health \n",
      "Organization's Mental Health Action Plan...\n",
      "Metadata: {'producer': 'PyPDF', 'creator': 'Microsoft Word', 'creationdate': '2023-12-31T03:50:13+00:00', 'author': 'IEEE', 'moddate': '2023-12-31T03:52:06+00:00', 'title': 's8329 final', 'source': 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}\n",
      "Min chunk size: 95 characters\n",
      "Max chunk size: 399 characters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the LangChain paper\n",
    "paper_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/96-FDF8f7coh0ooim7NyEQ/langchain-paper.pdf\"\n",
    "pdf_loader = PyPDFLoader(paper_url)\n",
    "pdf_document = pdf_loader.load()\n",
    "\n",
    "# Load content from LangChain website\n",
    "web_url = \"https://python.langchain.com/v0.2/docs/introduction/\"\n",
    "web_loader = WebBaseLoader(web_url)\n",
    "web_document = web_loader.load()\n",
    "\n",
    "# Create two different text splitters\n",
    "splitter_1 = CharacterTextSplitter(chunk_size=300, chunk_overlap=30, separator=\"\\n\")\n",
    "splitter_2 = CharacterTextSplitter(chunk_size=400,chunk_overlap=20,separator=\"\\n\")\n",
    "\n",
    "# Apply both splitters to the PDF document\n",
    "chunks_1 = splitter_1.split_documents(pdf_document)\n",
    "chunks_2 = splitter_2.split_documents(pdf_document)\n",
    "\n",
    "# Define a function to display document statistics\n",
    "def display_document_stats(docs, name):\n",
    "    \"\"\"Display statistics about a list of document chunks\"\"\"\n",
    "    total_chunks = len(docs)\n",
    "    total_chars = sum(len(doc.page_content) for doc in docs)\n",
    "    avg_chunk_size = total_chars / total_chunks if total_chunks > 0 else 0\n",
    "    \n",
    "    # Count unique metadata keys across all documents\n",
    "    all_metadata_keys = set()\n",
    "    for doc in docs:\n",
    "        all_metadata_keys.update(doc.metadata.keys())\n",
    "    \n",
    "    # Print the statistics\n",
    "    print(f\"\\n=== {name} Statistics ===\")\n",
    "    print(f\"Total number of chunks: {total_chunks}\")\n",
    "    print(f\"Average chunk size: {avg_chunk_size:.2f} characters\")\n",
    "    print(f\"Metadata keys preserved: {', '.join(all_metadata_keys)}\")\n",
    "    \n",
    "    if docs:\n",
    "        print(\"\\nExample chunk:\")\n",
    "        example_doc = docs[min(5, total_chunks-1)]  # Get the 5th chunk or the last one if fewer\n",
    "        print(f\"Content (first 150 chars): {example_doc.page_content[:150]}...\")\n",
    "        print(f\"Metadata: {example_doc.metadata}\")\n",
    "        \n",
    "        # Calculate length distribution\n",
    "        lengths = [len(doc.page_content) for doc in docs]\n",
    "        min_len = min(lengths)\n",
    "        max_len = max(lengths)\n",
    "        print(f\"Min chunk size: {min_len} characters\")\n",
    "        print(f\"Max chunk size: {max_len} characters\")\n",
    "\n",
    "# Display stats for both chunk sets\n",
    "display_document_stats(chunks_1, \"Splitter 1\")\n",
    "display_document_stats(chunks_2, \"Splitter 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88c947d-dd2b-4da7-b65c-f66bdcf62ce1",
   "metadata": {},
   "source": [
    "# Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9e5705d7-6c23-4fdf-b9dc-3ee1feebc3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OllamaEmbeddings(model=\"llama3\")\n",
    "\n",
    "docsearch = Chroma.from_documents(chunks_1,embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3170cd0-6cf9-41cd-aea6-ab0b9210d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = 'langchain'\n",
    "\n",
    "docs = docsearch.similarity_search(QUERY)\n",
    "print(docs.page_content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a2169b-adc9-4de7-b2b3-bf57b449101e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
